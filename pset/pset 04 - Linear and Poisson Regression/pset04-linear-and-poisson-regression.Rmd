---
title: "PSET 04 - Linear regression, Poisson Regression"
author: "S&DS 361"
date: "2024-02-21"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pubtheme)
```

## Part 1: Data acquisition and cleaning

#### 1. Add comments to `get.flight.location.data.r`

The R script `get.flight.location.data.r` contains code that scrapes flight location data from ADSBexchange.com. It is pasted below. The script contains no comments (except at the very top of the script). Please add comments to the code below everywhere there is a `##` explaining what that chunk of code does. 

You don't need to write paragraphs, just a line or two for each one. Many of the functions below will look familiar, but some may be new to you and will require you to check R help or the interwebs. Feel free to run the code (by, for example, copying it into it's own R script and running line by line) to check what the outputs are before writing your comment. You'll need to create a folder called `data/flight-locations` in order for the last line of the code to run. I suggest changing the for loop to say `j in 1:2` instead of `j in 1:nrow(du)` so that you can test the code without having to wait for all the data to download.


```
## get.flight.location.data.r
## scrape data from adsbexchange
## Got URL from the May example under readsb-hist that was give here
## https://www.adsbexchange.com/data-samples/
library(tidyverse)
library(jsonlite)

## create a data frame with three columns, where 'sec' goes from 0 to 55 in increments of 5, 'min' goes from 0 to 59 with interger increment, and 'hr' goes from 0 to 23 with interger increment.
du = expand.grid(sec=seq(0,55, by=5), 
                 min=0:59, 
                 hr=0:23)

## select the columns 'hr', 'min', and 'sec' from the data frame and print theb first 6 rows
du = du %>% 
  select(hr, min, sec) 
head(du)

## pad the values in 'hr', 'min', and 'sec' with a 0 if they are less than 2 characters long
du = du %>% 
  mutate(hr  = str_pad(hr , 2, pad='0'), 
         min = str_pad(min, 2, pad='0'), 
         sec = str_pad(sec, 2, pad='0'))

## add a column named 'url' to the data frame that contains strings concatenated by the url, the values in 'hr', 'min', and 'sec', and 'Z.json.gz'. Print the first 6 rows of the data frame.
du = du %>% 
  mutate(url = paste0('https://samples.adsbexchange.com/readsb-hist/2022/12/01/', 
                      hr, min, sec, 
                      'Z.json.gz'))
head(du)                

## Select the rows where the values in 'min' are multiples of 10 and the values in 'sec' are 00. 
du = du %>%
  filter(as.numeric(min) %% 10 ==0, 
         sec=='00')

## We are going to get the data from the web directed by the urls in the 'url' column. We need to loop over all columns 
for(j in 1:nrow(du)){
  
  cat(j, '')
  
  ## create a temp.url object that is the url in the 'url' column, and read the json file from the url into a data frame
  temp.url = du$url[j]
  temp.url = url(temp.url)
  con = gzcon(temp.url)
  d = fromJSON(con)
  
  ## select the 'aircraft' column from the data frame we crawled from the url
  d = d$aircraft
  
  ## find the time part of the url by regular expression and save it using 'filename'. Then save the data frame to the directory 'data/flight-locations/' a rds file with the name 'filename'
  filename = gsub('.+/', '', du$url[j])
  filename = gsub('[.].+', '', filename)
  filename = paste0('data/flight-locations/', filename, '.rds')
  saveRDS(d, file=filename)
  
}
```


#### 2. Add comments to `clean.flight.location.data.r`

The R script `clean.flight.location.data.r` contains code that clean the data obtained by `get.flight.location.data.r`. The script is pasted below. It also contains no comments. Please add comments everywhere there is a `##` explaining what that chunk of code does. 

You don't need to write paragraphs, just a line or two for each one. Many of the functions below will look familiar, but some may be new to you and will require you to check R help or the interwebs. Feel free to run the code (by, for example, copying it into it's own R script) to check what the outputs are before writing your comment.

```
## clean.flight.location.data.r
## clean the flight location data obtained by using get.flight.location.data.r

## extract all files from the directory 'data/flight-locations/' and save their names to 'filenames' object
filenames = dir('data/flight-locations/', full.names = T)
head(filenames)

## create a data frame with no rows and columns named 'df'
df = NULL

## loop over all the filenames in 'filenames'
for(filename in filenames){
  
  ## extract the time part of the filename and save it to 'time'. Then extract the hour and minute from 'time' and save them to 'hr' and 'min'. 
  time = gsub('.+[/]|Z.+', '', filename)
  hr = substr(time, 1, 2)
  min= substr(time, 3, 4)
  
  ## paste the values in 'hr' and 'min' together and save it to 'time'. Then convert 'hr' and 'min' to numeric. Read the rds file from the 'filename' and save it to 'd'.
  time = paste0(hr, ":", min)
  hr = as.numeric(hr)
  min= as.numeric(min)
  
  cat(time, '')
  
  d = readRDS(filename)
  
  ## Manipulate 'd' and store the new data frame in 'dd'
  dd = d %>%
    
    ## unnest the lastPosition column by '.' and create different columns for each element of the list
    unnest(lastPosition, names_sep = '.') %>% 
    
    mutate(
      
      ## remove white spaces from strings in fight columna
      flight = trimws(flight), 
      
      ## substitute NA’s in order to fill in missing values for lat and lon
      lat = ifelse(!is.na(lat), lat, rr_lat),
      lon = ifelse(!is.na(lon), lon, rr_lon),
      lat = ifelse(is.na(lat) & lastPosition.seen_pos<=600, lastPosition.lat, lat),
      lon = ifelse(is.na(lon) & lastPosition.seen_pos<=600, lastPosition.lon, lon),
      
      ## subsitute ’ground’ with 0’s in order to make the column all numeric and convert it to numeric vaues, then create a new column `alt` that is alt_geom if it is not an NA, otherwise it is alt_baro
      alt_baro = ifelse(alt_baro=='ground', 0       , alt_baro),
      alt_baro = as.numeric(alt_baro),
      alt      = ifelse(!is.na(alt_geom)  , alt_geom, alt_baro),
      
      ## create a new column `speed` that is gs if it is not an NA, otherwise it is tas
      speed   = ifelse(!is.na(gs), gs, tas),
      
      ## create a new column `heading` that is track if it is not an NA, if `track is NA and `true_heading` is not NA, it is `true_heading`, and if both are NA but `nav_heading` is not NA, then it is nav_heading, for the case all three is NA, it is `track`.
      heading = case_when(
        !is.na(track)                                             ~ track,
        is.na(track) & !is.na(true_heading)                       ~ true_heading,
        is.na(track) &  is.na(true_heading) & !is.na(nav_heading) ~ nav_heading, 
        TRUE ~ track), 
      
      ## create new 'hr', 'min' and 'time' columns using the extracted values from the filename
      hr  =  hr, 
      min = min, 
      time = time) %>%
    
    ## select the columns 'hex', 'type', 'flight', 'lat', 'lon', 'alt', 'speed', 'heading', 'hr', 'min', and 'time' from the data frame
    select(hex, type, flight, lat, lon, alt, speed, heading, hr, min, time) %>%
    
    ## filter out rows where 'alt' is 0
    filter(alt!=0)
  
  ## append 'dd' to 'df'
  df = rbind(df, dd)
  
}

saveRDS(df, file='data/flight.locations.rds')

```

## Part 2: Linear regression

#### 3. Different codings for categorical variables

Suppose you are predicting `log(value)` in our `branford.csv` data set. Suppose you build one model with `log(living)`, `grade`, and `style` as predictors, and for a second model you use `relevel` to choose `Mobile Home` as the reference level for the `style` variable, instead of using the default reference `Bungalow` that `lm` uses in the first model. Show that 

- the predictions obtained from the two models are the same
- the CIs and PIs are the same
- adjusted R^2 is the same
- the intercept differs by a constant
- the coefficients for `style` all differ by the same constant 
- the coefficients of `Mobile Home` in model 1 and `Bungalow` in model 2 are that same constant or -1*constant. 
- all other coefficients (`log(living)` and `grade`) and standard errors are the same (up to 13 decimal places)

```{r}
d = read.csv('data/branford.csv')
head(d)
```
```{r}
lm1 = lm(log(value) ~ log(living) + grade + style, data=d)
dd = d %>% 
  mutate(style = relevel(factor(style), ref = "Mobile Home"))
lm2 = lm(log(value) ~ log(living) + grade + style, data=dd)
summary(lm1)
summary(lm2)
```


From the summary, we immediately get the R^2 values of the two models are the same. The next trunk of code shows that the log(living) and all grade coefficients of the two models are the same up to a very small number. Their standard error is also same up to a small number. The intercept is differed by a constant.

```{r}
for (i in 1:11) {
  print(paste("lm1:", names(lm1$coefficients)[i], "lm2: ", names(lm2$coefficients)[i]))
  print(as.numeric(lm1$coefficients[i] - lm2$coefficients[i]))
  print(sqrt(diag(vcov(lm1)))[i] - sqrt(diag(vcov(lm2)))[i])
}
```


The next trunk of code shows that the coefficients for style all differ by the same constant. The coefficients of Mobile Home in model 1 and Bungalow in model 2 are -1*constant.

```{r}
for (i in 12:19) {
  if(i < 16)
    j = i + 1
  else {
    i = i + 1
    j = i
  }
  print(paste("lm1:", names(lm1$coefficients)[i], "lm2", names(lm2$coefficients)[j]))
  print(as.numeric(lm1$coefficients[i] - lm2$coefficients[j]))
}
print('lm1 mobile home / lm2 bungalow')
print(as.numeric(lm1$coefficients[16] / lm2$coefficients[12]))

```
We finally check the predictions, CIs and PIs are the same. We've finished all sanity checks.

```{r}
library(MLmetrics, warn.conflicts = FALSE)
new_data <- data.frame(value = sample(min(d$value):max(d$value), 10),
                        living = sample(min(d$living):max(d$living), 10),
                        grade = sample(d$grade, 10),
                        style = sample(d$style, 10))
error = MSE(predict(lm1, new_data), predict(lm2, new_data))
cat('MSE difference: ', error)

lm1.pred <- predict(lm1, newdata = new_data, interval = "prediction")
lm2.pred <- predict(lm2, newdata = new_data, interval = "prediction")
print('PI difference: ')
print(lm2.pred - lm1.pred)

lm1.conf <- predict(lm1, newdata = new_data, interval = "confidence")
lm2.conf <- predict(lm2, newdata = new_data, interval = "confidence")
print('CI difference: ')
print(lm2.conf - lm1.conf)


```




#### 4. Simulation

Suppose $y$ has a linear, non-deterministic relationship with $x$ that can be represented by the model $y = 1 + 2x + \epsilon$, where $\epsilon \sim N(0,1)$. Simulate some data by doing the following: 

a. Create a random sample of 10,000 $x$ values on $[0,1]$.
b. Create a random sample of 10,000 $\epsilon$ values from $N(0,1)$.
c. Create a random sample of 10,000 $y$ values using $y = 1 + 2x + \epsilon$.


We first create the data in the following trunk.
```{r}
## Data creation
set.seed(1)
x = runif(10000, 0, 1)
epsilon = rnorm(10000, 0, 1)
y = 1 + 2*x + epsilon
```


Then, 

d. Fit a simple linear regression model to the data and report the estimated coefficients and estimated model standard deviation. Are the estimates what you would expect? Why or why not? 
```{r}
## Fit a simple linear regression model
lm = lm(y ~ x)
summary(lm)
print(sigma(lm))
```
From the summary, we can see that the estimated intercept is 0.98049 and the estimated x-slope is 2.00706. The estimated model standard deviation is 0.9890432. The estimates are what we would expect. The true model is $y = 1 + 2x + \epsilon$, where the variance of $\epsilon$ is 1, and the estimates are very close to the true values.

e. Plot the scatter plot of $y$ versus $x$, and add a regression line to the plot. Does this visualization look as you would have expected? Do the linear regression assumptions appear to hold? Why or why not? 

```{r}
## Scatter plot of y versus x
ggplot(data.frame(x, y), aes(x, y)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  ggtitle("Scatter plot of y versus x") +
  theme_pub()

```
The scatter plot of y versus x looks as we would have expected. We will verify the linear model assumptions in the next trunk.

```{r, fig.height=5, fig.width=5}
## Check linear model assumptions
par(mfrow = c(2, 2))
plot(lm)

```

I confirmed that the linear assumptions are met because: 1. x and y tend to have a linear relationship2. the residuals are normally distributed from the Q-Q plot 3. The residuals are homoscedastic from the scale-location plot 4. The residuals are independent from the residuals versus leverage plot.

## Part 3: Poisson Regression

### ChatGPT
#### 5. After asking ChatGPT "What is Poisson Regression?" I then asked "why couldn't I use linear regression instead?" Part of ChatGPT's response is below.  For each bullet point, name at least one part of ChatGPT's response that isn't *quite* accurate. 

- "Linear regression assumes that the response variable is continuous and \textcolor{red}{normally distributed}, and it is not suitable for modeling count data that is typically discrete and \textcolor{red}{non-negative}"

Linear regression model can be applied to non-negative data. And the normally distribution assumption is for the residuals, not the response variable.

- "Furthermore, Poisson regression models the natural logarithm of the mean of the response variable as a linear function of the predictor variables, which can handle situations where \textcolor{red}{the mean and variance of the response variable are not equal}."

The property of Poisson distribution is that the mean and variance are equal. For situations that mean and variance of the response variable are not equal, we should not use Poisson regression.


### Tesla's Safety Score

Tesla uses data collected on each driver (using their cameras and possibly other sensors) to create a Safety Score for that driver. According to [Tesla's website](https://www.tesla.com/support/safety-score#version-2.0), "The Safety Score (Beta) is an assessment of your driving behavior based on several metrics called Safety Factors. These are combined to estimate the likelihood that your driving could result in a future collision... The Safety Score (Beta) is intended to provide drivers transparency and feedback of their driving behaviors to encourage safer driving and potentially pay less for their insurance. The Safety Score is a value between 0 and 100, where a higher score indicates safer driving. Most drivers are expected to have a Safety Score of 80 or above."

Tesla publishes the formulas they use to compute the Safety Score. "In order to calculate your daily Safety Score, we use the Predicted Collision Frequency (PCF) formula below to predict how many collisions may occur per 1 million miles driven, based on your driving behaviors measured by your Tesla vehicle."

$$ \textrm{Predicted Collision Frequency (PCF)} = 0.83220180 
\times 1.012555104^{\textrm{Forward Collision Warnings per 1,000 Non-Autopilot Miles}} \\
\times 1.16460827^{\textrm{Hard Braking}} \\
\times 1.01498152^{\textrm{Aggressive Turning}} \\
\times 1.00245084^{\textrm{Unsafe Following Time}} \\
\times 1.40663310^{\textrm{Forced Autopilot Disengagement}} \\
\times 1.05018975^{\textrm{Late Night Driving}} \\
\times 1.00939791^{\textrm{Excessive Speeding}} \\
\times 1.00901189^{\textrm{Unbuckled Driving}}
$$

The Safety Factors like "Hard Breaking" are described on the page linked above. They convert the PCF to the Safety Score using 

$$ \textrm{Safety Score} = 112.29263237 - 14.77121589 \cdot \textrm{PCF} $$

#### 6. The PCF formula looks like it could be the result of fitting a Poisson regression model to their Safety Factors and collisions data. Discuss why a Poisson Regression model would or would not be a reasonable model for this data. 

Poisson regression model would be a reasonable model for this data because the response variable is the number of collisions, which is a count data. The car accidents can be interpreted as an event with a constant rate of occurance but random in time. The Poisson distribution is a good model for this kind of data.

#### 7. Let's assume the PCF formula did in fact come from a Poisson Regression model. What was $\beta_{\textrm{Hard Breaking}}$, the coefficient for Hard Breaking, in that model? 

The coefficient for Hard Breaking in the Poisson Regression model is $\beta_{\textrm{Hard Breaking}} = \log(1.16460827) = 0.152$.



#### 8. What is the interpretation of the term $1.16460827^{\textrm{Hard Braking}}$ in the PCF formula?


The term $1.16460827^{\textrm{Hard Braking}}$ in the PCF formula is the multiplicative effect of a one unit increase in the Hard Braking on the predicted collision frequency. It means that for a one unit increase in the Hard Braking, the predicted collision frequency is multiplied by 1.16460827. In other words, one unit increase of Hard Braking will lead to $\log(1.164) = 0.152$ increase in the logarithm of predicted collision frequency.


### EV charging stations

The following data set is census data set from earlier in the course with new columns added that have the number of Level 2 (`lev2`) and Level 3 (`lev3`) electric vehicle charging stations for each census tract (`GEOID`). 

```{r}
dc = readRDS('data/tracts.and.census.with.EV.stations.rds')
dc = dc@data ## keep just the data frame, not the polygons
dc = dc %>% 
  
  ## Change NAs to 0s, and 
  ## since charging stations seem to come in pairs, create new columns
  ## for pairs of charging stations
  mutate(lev2 = ifelse(is.na(lev2), 0, lev2), 
         lev3 = ifelse(is.na(lev3), 0, lev3), 
         lev2pairs = round(lev2/2),
         lev3pairs = round(lev3/2)) %>%
  
  ## Keep tracts with at least one charging station, 
  ## and get rid of a couple of outliers
  filter((lev2!=0 | lev3!=0) & lev2 <= 50) 


```

#### 9. Suppose we want to quickly determine if the number of Level 2 charging stations in a census track looks roughly Poisson. (For this problem, consider all the data at once, not just the data for smaller subsets of $x$.) Let's compare the data to a Poisson distribution with the same mean as the data.  Plot the actual distribution of the data along with this Poisson distribution in a way that allows for a quick comparison of the two. Does the number pairs of Level 2 charging stations in a census tract look Poisson distributed?

```{r}
# find the mean 
poisson_x = min(dc$lev2):max(dc$lev2)
poisson_y = dpois(poisson_x, mean(dc$lev2))
p = data.frame(x = poisson_x, y = poisson_y)
dc %>% 
  ggplot(aes(lev2)) + 
  geom_histogram(aes(y=..density..), fill = "lightblue", color = "black") + 
  geom_line(data = p, aes(x, y), color = "red") + 
  ggtitle("Distribution of Level 2 charging stations") + 
  theme_pub()

```
The data looks roughly Poisson distributed, but the peak is left skewed than the theoretical Poisson distribution. The number of pairs of Level 2 charging stations in a census tract looks Poisson distributed. We might use a proper mean parameter to model this.

#### 10. Fit a Poisson Regression model for predicting Level 2 charging stations in a census tract using `house.value` and `age`. How does this model compare to the null model (the model with only an intercept term)? Considering your observations in #9, what outputs of this model are reasonable/unreasonable? 

```{r}
## Fit a Poisson Regression model
m1 = glm(lev2 ~ house.value + age, data=dc, family=poisson)
summary(m1)

```

The residual deviance is much smaller than the null deviance, which indicates that the Poisson model is better than the null model. Note that all factors in the model is significant with a very low P-value, hence we are confident that we can conclude strong statistical evidence from our model. With the result from #9, we can conclude that the Poisson model is reasonable for the data if we choose house.value and age as our predictor. 

